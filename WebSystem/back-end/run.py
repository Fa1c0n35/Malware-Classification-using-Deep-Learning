
import re
import json
import warnings
warnings.simplefilter(action='ignore', category=UserWarning)

from app.model.autoencoder import AutoEncoder
from app.model.mlp import MultilayerPerceptron
from app.torchviz import make_dot
from app.db import sqlite_db
import app.predict_utils as predict_utils
import app.utils as utils

from flask import Flask
from flask import jsonify
from flask import request
from flask_cors import CORS

import torch

app = Flask(__name__)
CORS(app)
app.config.from_pyfile('config.cfg', silent=True)


@app.route('/predict', methods=['POST'])
def predict_from_hash():

    try:

        if request.method == 'POST':

            file = request.files['file']
            if file:

                vt_json_data = file.read().decode('utf-8')
                
                if 'additional_info' not in vt_json_data:
                    raise ValueError('PredictError: Not a valid behaviors data file!')

                vt_json_data = json.loads(vt_json_data)
                file_hash = vt_json_data['sha256']

                if sqlite.fetch_by_hash(file_hash):
                    raise ValueError(
                        'PredictError: This sample has already existed inside database!')

                # extract unigrams from behaviors raw string
                malware_unigrams = predict_utils.preprocess_json(vt_json_data)

                # generate bit-string based on top-unigrams
                malware_bitstr = predict_utils.unigrams_to_bitstring(
                    malware_unigrams, top_unigrams)

                # generate signatures using Denoise AutoEncoders (DAE)
                malware_sign = predict_utils.gen_signs_from_bitstring(
                    dae, malware_bitstr)

                # using generated signature for prediction
                prediction_probability, malware_predicted = predict_utils.predict_from_malware_sign(
                    mlp, malware_sign, app.config['MLP_LABEL_INDEX'])

                # push all into database for future reference
                sqlite.insert_into_db(
                    [
                        file_hash, vt_json_data, malware_unigrams,
                        malware_bitstr, malware_sign[0], malware_predicted,
                        prediction_probability
                    ]
                )

                return "OK\t{}".format(file_hash)

    except Exception as e:
        return '{}'.format(e)


@app.route('/get-list-predicted-malwares')
def get_predicted_malwares():
    malware_list = sqlite.get_partial_list_data()
    if not len(malware_list):
        return 'NO PREDICTED MALWARE YET'
    column_name = ['SHA256', 'Time Added', 'Predicted As']
    for i, _ in enumerate(malware_list):
        malware_list[i] = dict(zip(column_name, malware_list[i]))
    return jsonify(malware_list)


@app.route('/get-predicted-malware/<file_hash>')
def view_predicted_malware(file_hash):
    malware_data = sqlite.fetch_by_hash(file_hash)
    if not malware_data:
        return 'NOT FOUND'
    return jsonify(malware_data)


@app.route('/get-umap-data')
def get_umap():
    return jsonify(umap_data)


@app.route('/trained-dataset-summary')
def dataset_summary():
    summary_label = []
    summary_data = []
    for k, v in summary.items():
        summary_label.append(k)
        summary_data.append(v.item())
    return jsonify({'Label': summary_label, 'Data': summary_data})


@app.route('/get-top-unigrams')
def get_top_unigram():
    return jsonify(top_unigrams[:200])


@app.route('/get-dae-graphviz')
def get_dae_graphviz():
    x = torch.randn(1, 10000).requires_grad_(True)
    _, decoded = dae(x)
    return make_dot(decoded, params=dict(list(dae.named_parameters()) + [('x', x)])).source


@app.route('/get-mlp-graphviz')
def get_mlp_graphviz():
    x = torch.randn(1, 20).requires_grad_(True)
    y = mlp(x)
    return make_dot(y, params=dict(list(mlp.named_parameters()) + [('x', x)])).source


@app.route('/')
def index():
    return "<h1>API endpoint :) Read the source, luke!</h1>"


if __name__ == '__main__':

    dae = utils.initialize_model(
        AutoEncoder, app.config['AUTOENCODER_TRAINED_LAYER_SIZE'],
        app.config['AUTOENCODER_TRAINED_MODEL_PATH'])

    mlp = utils.initialize_model(
        MultilayerPerceptron, app.config['MLP_TRAINED_LAYER_SIZE'],
        app.config['MLP_TRAINED_MODEL_PATH'])

    data, label, summary = utils.load_dataset(app.config['DATASET_PATH'])

    umap_data = utils.umap_transform(dae, data, label)

    top_unigrams = utils.load_unigram(app.config['TOP_UNIGRAMS'])

    sqlite = sqlite_db(app.config['SQLITE_DB_PATH'])

    print("Pre-processing done! Running the API server now...")

    app.run(debug=True)
