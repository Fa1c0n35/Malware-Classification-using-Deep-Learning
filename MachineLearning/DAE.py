
import os

import torch
import torch.utils.data

import pandas as pd
import numpy as np


class LoadDataset(torch.utils.data.Dataset):

    def __init__(self, dataset_path):
        """
        Args:
            dataset_path (string): path to dataset file
        """

        print("\nLoading datasets...")
        self.df = pd.read_csv(dataset_path)
        self.labels_unique = self.df.iloc[:, 0].unique().tolist()
        print("\n{}\n".format(self.df.iloc[:, 0].value_counts())

    def __getitem__(self, index):

        data = self.df.iloc[index, :]

        # ::BUG
        # snippet `torch.tensor(list(data[2:]))` uses really high amount of RAM,
        # doubling it usage for every iteration, i guess it has to do with
        # garbage collector is not invalidating old memory good enough
        val = torch.tensor(list(map(int, data[2:])))

        label = data[0]
        mal_hash = data[1]
        return (val, mal_hash, label)

    def __len__(self):
        return self.df.shape[0]


class AutoEncoder(torch.nn.Module):

    def __init__(self, layer_size):
        """
        Initialize the AutoEncoder class
        """

        # must have at least [input, hidden, output] layers
        assert len(layer_size) >= 3
        assert layer_size[0] == layer_size[-1]  # input equals output
        assert len(layer_size) % 2 == 1  # must have odd number of layers

        # initialize nn.Module object
        super(AutoEncoder, self).__init__()

        # save parameters
        self.layer_size = layer_size

        # prepare func locally
        self.relu = torch.nn.ReLU()

        self.layers = torch.nn.ModuleList()
        self.batchnorm = torch.nn.ModuleList()
        for i in range(len(self.layer_size)-1):
            self.layers.append(torch.nn.Linear(self.layer_size[i], self.layer_size[i+1]))
            if i < len(self.layer_size)-2:
                self.batchnorm.append(torch.nn.BatchNorm1d(self.layer_size[i+1]))

    def forward(self, x):

        # hidden layer
        encoded = None
        for i, (layer, batchnorm) in enumerate(zip(self.layers[:-1], self.batchnorm)):
            x = layer(x)
            x = batchnorm(x) # can only be applied for NxM, where N = batch size & M = data size
            x = self.relu(x)
            if i == len(self.layer_size)//2-1:  # get middle (thus encoded data)
                encoded = x

        decoded = self.layers[-1](x)

        return encoded, decoded


def main():

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    print("\nDevice used : {}".format('cuda' if torch.cuda.is_available() else 'cpu'))
    print("Pytorch version: {}".format(torch.__version__))

    if torch.cuda.is_available():
        print(torch.cuda.get_device_name(0))

    project_name = "DAE"

    # hyper parameters
    num_epochs          = 1000   # how many iterations for complete single dataset training
    learning_rate       = 0.001
    batch_size          = 50    # batch per-training
    enable_checkpoint   = True
    denoise_ratio       = 0.2
    checkpoint_name     = 'checkpoint-{}.pt'.format(project_name) # model filename
    layer_size          = [10000, 3000, 500, 100, 20, 100, 500, 3000, 10000]  # layers size

    # load dataset
    malware_data = LoadDataset(dataset_path='dataset.csv.xz')
    # shuffle=True means for every epoch, the data is going to be re-shuffled
    # pin_memory=True, ref: https://devblogs.nvidia.com/how-optimize-data-transfers-cuda-cc/
    train_loader = torch.utils.data.DataLoader(malware_data, batch_size=batch_size, pin_memory=True, shuffle=True)

    # setup appropriate objects
    dae = AutoEncoder(layer_size).to(device)
    criterion = torch.nn.BCEWithLogitsLoss()
    optimizer = torch.optim.Adam(dae.parameters(), lr=learning_rate)
    epoch = 0

    # load previous checkpoint if it exists
    if enable_checkpoint:
        if os.path.exists(checkpoint_name):
            print("Previous checkpoint model found!\n")
            checkpoint = torch.load(checkpoint_name)
            dae.load_state_dict(checkpoint['model_state_dict'])
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            epoch = checkpoint['epoch']
            dae.eval()

    def denoise(x, ratio):
        noise = np.random.binomial(1, ratio, size=x[0].shape[0])
        noise = torch.tensor(noise).float().to(device)
        return (x + noise) % 2

    # train our model
    while epoch < num_epochs:
        avg_loss = 0
        for i, (X, _, _) in enumerate(train_loader):

            dae.train()  # switch back to train mode

            x = X.float().to(device)
            x_noise = denoise(x, denoise_ratio)  # denoise input data
            _, outputs = dae(x_noise)
            loss = criterion(outputs, x)
            avg_loss += loss.item()

            optimizer.zero_grad()  # clear our previous calc
            loss.backward()        # calc all parameters gradient
            optimizer.step()       # apply weight tuning based on calculated gradient

            if (i+1) % 5 == 0:
                dae.eval()  # turns off dropout and batch normalization
                epoch_fmt = str(epoch+1).rjust(len(str(num_epochs)))
                batch_fmt = str(i+1).rjust(len(str(len(train_loader))))
                fmt_str = "Epochs [" + epoch_fmt + "/{}], Batch [" + batch_fmt + "/{}], Loss = {:.8f}"
                print(fmt_str.format(num_epochs, len(train_loader), loss.item()))

        avg_loss /= len(train_loader)
        if (epoch+1) % 5 == 0:
            print("\nAverage loss for epochs [{}] = {:.8f}".format(epoch+1, avg_loss))

        # generate compressed malware output for testing
        if (epoch+1) % 10 == 0:
            with torch.no_grad():
                # turns off dropout and batch normalization
                dae.eval()
                # save encoded form for all entire dataset
                filename = "encoded-form-{}.csv".format(project_name)
                encoded_data = []  # x, hash and label combined
                # calculate total losses from all batches
                for X, mal_hash, label in train_loader:
                    x = X.float().to(device)
                    encoded, _ = dae(x)
                    for each_encoded, each_hash, each_label in zip(encoded.tolist(), mal_hash, label):
                        encoded_data.append([each_label] + [each_hash] + each_encoded)
                # export current compressed file into csv for previewing
                print("\nExporting encoded malware form into csv..\n")
                encoded_df = pd.DataFrame(encoded_data)
                encoded_df.to_csv(filename, index=False, header=False)

        # save model for every 10 iterations -- make sure we don't lost everything
        if enable_checkpoint:
            if (epoch+1) % 10 == 0:
                print("\nSaving checkpoint model..\n")
                torch.save({
                    'epoch': epoch+1,
                    'model_state_dict': dae.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict()
                }, checkpoint_name)

        epoch += 1

    torch.save(dae.state_dict(), "{}-Trained-Model.pt".format(project_name))


if __name__ == '__main__':
    main()