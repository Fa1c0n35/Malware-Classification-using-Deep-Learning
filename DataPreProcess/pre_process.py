
import os
import glob
import re
import json
import argparse
import random
import pandas as pd


def preprocess_json(json_vt_data):

    # only take additional_info data
    behaviors_data = json.dumps(json_vt_data['additional_info'])
    behaviors_data = behaviors_data.replace('\n', ' ')  # split by newlines
    behaviors_data = re.sub(r'\s+', ' ', behaviors_data)  # remove many spaces into single space
    behaviors_data = re.sub(r'[a-fA-F\d]{32,128}', '', behaviors_data)  # remove hash
    behaviors_data = re.sub(r'\d+\.\d+', '', behaviors_data)
    unigrams = list(set(filter(None, behaviors_data.split())))  # remove empty string
    r = re.compile(r'^"|",?:?$|,$')
    unigrams = [r.sub('', unigram) for unigram in unigrams if r.search(unigram)] # remove some unuseful chars
    unigrams = [unigram.strip() for unigram in unigrams]  # strip each unigrams
    unigrams = [unigram for unigram in unigrams if len(unigram) > 3] # remove unigram if length <= 3
    return unigrams


def main():

    parser = argparse.ArgumentParser(description='Pre-process malware behaviors JSON files using unigrams counting technique.')
    parser.add_argument('dir', type=str, help='Directory containing JSON malware behaviors files.')
    parser.add_argument('-l', '--limit', type=int, default=10000, help='How many unigrams to take. (default: 10000)')
    parser.add_argument('-s', '--shuffle', type=bool, default=False, help='Shuffle bit-string ordering. (default: False)')
    args = parser.parse_args()

    dict_unigram = dict()
    json_unigrams_list = []
    behaviors_json = list(glob.glob("{}/*.json".format(args.dir)))

    print("\n[+] Splitting unigrams for every JSON files ...\n")

    for i, each_json in enumerate(behaviors_json):
        with open(each_json, 'r') as json_fi:

            if i % 10 == 0:
                print("\33[2K\rProcessing [{}/{}] -- {}".format(i, len(behaviors_json), each_json), end='')

            unigrams = preprocess_json(json.loads(json_fi.read()))
            json_unigrams_list.append(unigrams)

            for unigram in unigrams:
                dict_unigram[unigram] = 1 if unigram not in dict_unigram else dict_unigram[unigram] + 1

    print("\33[2K\r[+] Choosing {} top unigrams from most frequent unigrams ...".format(args.limit))

    top_unigrams = []

    for key, val in dict_unigram.items():
        if val < len(behaviors_json)-10:  # if occurs to all files
            top_unigrams.append((key, val))
    top_unigrams.sort(reverse=True, key=lambda x: x[1])
    top_unigrams = top_unigrams[:args.limit]
    if args.shuffle:
        random.shuffle(top_unigrams)

    print("\n[+] Converting all files' unigrams into bit-string based on top-frequent unigrams ...\n")

    bit_string_list = []

    for i, json_unigram in enumerate(json_unigrams_list):
        if i % 10 == 0:
            print("\33[2K\rProcessing {}/{}".format(i, len(json_unigrams_list)), end='')
        json_unigram = set(json_unigram)  # for faster lookup O(n log n)
        bit_string = [int(frequent_unigram in json_unigram) for frequent_unigram, count in top_unigrams]
        bit_string_list.append(bit_string)

    print("\33[2K\r[+] Saving into dataset.tar.xz and top_unigrams.txt ...\n")

    dataset_list = []

    for filename, bit_string in zip(behaviors_json, bit_string_list):
        label, filehash = os.path.basename(filename).split('_')
        filehash = filehash.split('.')[0]
        dataset_list.append([label] + [filehash] + bit_string)

    with open('top_unigrams.txt', 'w') as top_unigrams_fo:
        top_unigrams_fo.write('\n'.join(['\t'.join(str(x) for x in each_unigram) for each_unigram in top_unigrams]))

    df = pd.DataFrame(dataset_list)
    df.to_csv('dataset.csv.xz', index=False, compression='xz')


if __name__ == '__main__':
    main()